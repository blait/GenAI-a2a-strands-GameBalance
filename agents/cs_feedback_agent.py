#!/usr/bin/env python3
from strands import Agent, tool
from strands.multiagent.a2a import A2AServer
from strands.models.bedrock import BedrockModel
from a2a.server.tasks import InMemoryTaskStore  # Task Store ì¶”ê°€
from fastapi import FastAPI
from pydantic import BaseModel
import uvicorn
import asyncio

FEEDBACK_DATA = [
    {"race": "Terran", "complaint": "í…Œë€ ë§ˆë¦° ëŸ¬ì‹œê°€ ë„ˆë¬´ ê°•ë ¥í•©ë‹ˆë‹¤. ì´ˆë°˜ ë°©ì–´ê°€ ë¶ˆê°€ëŠ¥í•´ìš”.", "upvotes": 245, "urgency": "high", "date": "2025-10-01"},
    {"race": "Zerg", "complaint": "ì €ê·¸ ë®¤íƒˆì´ ë„ˆí”„ë˜ì–´ì„œ ì´ì œ ì“¸ëª¨ê°€ ì—†ìŠµë‹ˆë‹¤.", "upvotes": 312, "urgency": "high", "date": "2025-10-01"},
    {"race": "Protoss", "complaint": "í”„ë¡œí† ìŠ¤ ê´‘ì „ì‚¬ ì²´ë ¥ì´ ë„ˆë¬´ ì•½í•©ë‹ˆë‹¤.", "upvotes": 189, "urgency": "medium", "date": "2025-10-02"},
    {"race": "Terran", "complaint": "í…Œë€ ë²™ì»¤ ê±´ì„¤ ì†ë„ê°€ ë„ˆë¬´ ë¹¨ë¼ì„œ ëŸ¬ì‹œ ë°©ì–´ê°€ ì‰½ìŠµë‹ˆë‹¤.", "upvotes": 201, "urgency": "high", "date": "2025-10-03"},
    {"race": "Zerg", "complaint": "ì €ê·¸ íˆë“œë¼ ì‚¬ê±°ë¦¬ê°€ ì§§ì•„ì„œ ì“¸ëª¨ê°€ ì—†ì–´ìš”.", "upvotes": 156, "urgency": "medium", "date": "2025-10-03"},
    {"race": "Protoss", "complaint": "í”„ë¡œí† ìŠ¤ ìŠ¤í†° ë°ë¯¸ì§€ê°€ ë„ˆë¬´ ê°•ë ¥í•©ë‹ˆë‹¤.", "upvotes": 267, "urgency": "high", "date": "2025-10-04"},
]

@tool
def get_feedback(urgency: str = None, race: str = None) -> str:
    """Get customer feedback from game forums
    
    Args:
        urgency: Filter by urgency level (high, medium, low)
        race: Filter by race (Terran, Zerg, Protoss)
    """
    filtered = FEEDBACK_DATA
    if urgency:
        filtered = [f for f in filtered if f["urgency"] == urgency]
    if race:
        filtered = [f for f in filtered if f["race"] == race]
    
    result = []
    for f in filtered:
        result.append(f"[{f['race']}] {f['complaint']} (ì¶”ì²œ: {f['upvotes']}, ë‚ ì§œ: {f['date']})")
    
    return "\n".join(result) if result else "No feedback found"

# Agent ìƒì„±
agent = Agent(
    name="CS Feedback Agent",
    description="ê²Œì„ í¬ëŸ¼ì—ì„œ ê³ ê° í”¼ë“œë°±ì„ ì¡°íšŒí•˜ëŠ” ì—ì´ì „íŠ¸",
    model=BedrockModel(model_id="us.amazon.nova-lite-v1:0", temperature=0.3),
    tools=[get_feedback],
    system_prompt="""ë‹¹ì‹ ì€ ê³ ê° ì§€ì› ë‹´ë‹¹ìì…ë‹ˆë‹¤. 

**ë„êµ¬ ì‚¬ìš©ë²•:**
- get_feedback(): ëª¨ë“  í”¼ë“œë°± ì¡°íšŒ (í•„í„° ì—†ìŒ)
- get_feedback(race="Terran"): íŠ¹ì • ì¢…ì¡± í”¼ë“œë°±ë§Œ ì¡°íšŒ
- get_feedback(urgency="high"): ê¸´ê¸‰ë„ë³„ í”¼ë“œë°± ì¡°íšŒ
- get_feedback(race="Terran", urgency="high"): ë³µí•© í•„í„°

**ì¤‘ìš”:**
1. í•„í„°ë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ëª¨ë“  í”¼ë“œë°±ì´ ë°˜í™˜ë©ë‹ˆë‹¤
2. ë„êµ¬ë¥¼ í•œ ë²ˆë§Œ í˜¸ì¶œí•˜ì„¸ìš” (ë°˜ë³µ í˜¸ì¶œ ê¸ˆì§€)
3. ë„êµ¬ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•˜ì„¸ìš”

**ë©€í‹°í„´ ëŒ€í™” ì§€ì›:**
ì´ ì—ì´ì „íŠ¸ëŠ” A2A Taskë¥¼ í†µí•´ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.

**ì¤‘ìš”: ëª¨ë“  ì‘ë‹µì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”.**"""
)

# HTTP API (ì„ íƒì  - ë””ë²„ê¹…ìš©)
app = FastAPI()

class QueryRequest(BaseModel):
    query: str

@app.post("/ask")
async def ask(request: QueryRequest):
    result = await asyncio.to_thread(lambda: agent(request.query))
    return {"query": request.query, "response": result}

@app.post("/ask_stream")
async def ask_stream(request: QueryRequest):
    """Streaming endpoint for real-time thinking"""
    from fastapi.responses import StreamingResponse
    import json
    import queue
    import threading
    import sys
    
    event_queue = queue.Queue()
    
    class StreamCapture:
        def __init__(self, queue, original):
            self.queue = queue
            self.original = original
            
        def write(self, text):
            self.original.write(text)
            self.original.flush()
            if text and text.strip():
                self.queue.put(('log', text))
                
        def flush(self):
            self.original.flush()
    
    def run_agent():
        try:
            old_stdout = sys.stdout
            sys.stdout = StreamCapture(event_queue, old_stdout)
            
            print(f"\nğŸ¯ Query: {request.query}\n")
            
            result = agent(request.query)
            
            sys.stdout = old_stdout
            
            if hasattr(result, 'message') and hasattr(result.message, 'content'):
                content = result.message.content[0].text if result.message.content else ""
            else:
                content = str(result)
            
            event_queue.put(('answer', content))
            event_queue.put(('done', None))
        except Exception as e:
            event_queue.put(('error', str(e)))
    
    async def generate():
        thread = threading.Thread(target=run_agent, daemon=True)
        thread.start()
        
        while True:
            try:
                event_type, data = event_queue.get(timeout=0.1)
                
                if event_type == 'done':
                    yield f"data: {json.dumps({'type': 'done'})}\n\n"
                    break
                elif event_type == 'error':
                    yield f"data: {json.dumps({'type': 'error', 'content': data})}\n\n"
                    break
                elif event_type == 'log':
                    yield f"data: {json.dumps({'type': 'thinking', 'content': data})}\n\n"
                else:
                    yield f"data: {json.dumps({'type': event_type, 'content': data})}\n\n"
            except queue.Empty:
                await asyncio.sleep(0.1)
        
        thread.join(timeout=1)
    
    return StreamingResponse(generate(), media_type="text/event-stream")

def main():
    print("ğŸ“ Starting CS Feedback Agent...")
    print("  - A2A Server on port 9001 (with Task Store)")
    print("  - HTTP API on port 9002")
    
    # Task Store ìƒì„± (ëŒ€í™” íˆìŠ¤í† ë¦¬ ìë™ ê´€ë¦¬)
    task_store = InMemoryTaskStore()
    
    # A2A Server ì‹œì‘ (Task Store í¬í•¨)
    import threading
    a2a_server = A2AServer(
        agent=agent, 
        port=9001,
        task_store=task_store  # ğŸ‘ˆ Task Store í™œì„±í™”
    )
    a2a_thread = threading.Thread(target=a2a_server.serve, daemon=True)
    a2a_thread.start()
    
    print("  âœ… A2A Task Store enabled - Multi-turn conversations supported!")
    
    # Start FastAPI server
    uvicorn.run(app, host="127.0.0.1", port=9002)

if __name__ == "__main__":
    main()
